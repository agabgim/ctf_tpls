<center><a href="mpimesg.c">Actual source code: mpimesg.c</a></center><br>

<html>
<head> <link rel="canonical" href="http://www.mcs.anl.gov/petsc/petsc-current/src/sys/utils/mpimesg.c.html" />
<title></title>
<meta name="generator" content="c2html 0.9.4">
<meta name="date" content="2020-02-04T16:32:26+00:00">
</head>

<body bgcolor="#FFFFFF">
   <div id="version" align=right><b>petsc-3.12.4 2020-02-04</b></div>
   <div id="bugreport" align=right><a href="mailto:petsc-maint@mcs.anl.gov?subject=Typo or Error in Documentation &body=Please describe the typo or error in the documentation: petsc-3.12.4 v3.12.4 src/sys/utils/mpimesg.c.html "><small>Report Typos and Errors</small></a></div>
<pre width="80">

<a name="line2">  2: </a> #include <A href="../../../include/petscsys.h.html">&lt;petscsys.h&gt;</A>


<a name="line5">  5: </a><font color="#B22222">/*@C</font>
<a name="line6">  6: </a><font color="#B22222">  <a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html#PetscGatherNumberOfMessages">PetscGatherNumberOfMessages</a> -  Computes the number of messages a node expects to receive</font>

<a name="line8">  8: </a><font color="#B22222">  Collective</font>

<a name="line10"> 10: </a><font color="#B22222">  Input Parameters:</font>
<a name="line11"> 11: </a><font color="#B22222">+ comm     - Communicator</font>
<a name="line12"> 12: </a><font color="#B22222">. iflags   - an array of integers of length sizeof(comm). A '1' in ilengths[i] represent a</font>
<a name="line13"> 13: </a><font color="#B22222">             message from current node to ith node. Optionally NULL</font>
<a name="line14"> 14: </a><font color="#B22222">- ilengths - Non zero ilengths[i] represent a message to i of length ilengths[i].</font>
<a name="line15"> 15: </a><font color="#B22222">             Optionally NULL.</font>

<a name="line17"> 17: </a><font color="#B22222">  Output Parameters:</font>
<a name="line18"> 18: </a><font color="#B22222">. nrecvs    - number of messages received</font>

<a name="line20"> 20: </a><font color="#B22222">  Level: developer</font>

<a name="line22"> 22: </a><font color="#B22222">  Notes:</font>
<a name="line23"> 23: </a><font color="#B22222">  With this info, the correct message lengths can be determined using</font>
<a name="line24"> 24: </a><font color="#B22222">  <a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html#PetscGatherMessageLengths">PetscGatherMessageLengths</a>()</font>

<a name="line26"> 26: </a><font color="#B22222">  Either iflags or ilengths should be provided.  If iflags is not</font>
<a name="line27"> 27: </a><font color="#B22222">  provided (NULL) it can be computed from ilengths. If iflags is</font>
<a name="line28"> 28: </a><font color="#B22222">  provided, ilengths is not required.</font>

<a name="line30"> 30: </a><font color="#B22222">.seealso: <a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html#PetscGatherMessageLengths">PetscGatherMessageLengths</a>()</font>
<a name="line31"> 31: </a><font color="#B22222">@*/</font>
<a name="line32"> 32: </a><strong><font color="#4169E1"><a name="PetscGatherNumberOfMessages"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</a>  <a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html#PetscGatherNumberOfMessages">PetscGatherNumberOfMessages</a>(<a href="../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</a> comm,const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> iflags[],const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> ilengths[],<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> *nrecvs)</font></strong>
<a name="line33"> 33: </a>{
<a name="line34"> 34: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a>    size,rank,*recv_buf,i,*iflags_local = NULL,*iflags_localm = NULL;

<a name="line38"> 38: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm,&amp;size);
<a name="line39"> 39: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(comm,&amp;rank);

<a name="line41"> 41: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</a>(size,&amp;recv_buf,size,&amp;iflags_localm);

<a name="line43"> 43: </a>  <font color="#B22222">/* If iflags not provided, compute iflags from ilengths */</font>
<a name="line44"> 44: </a>  <font color="#4169E1">if</font> (!iflags) {
<a name="line45"> 45: </a>    <font color="#4169E1">if</font> (!ilengths) <a href="../../../docs/manualpages/Sys/SETERRQ.html#SETERRQ">SETERRQ</a>(<a href="../../../docs/manualpages/Sys/PETSC_COMM_SELF.html#PETSC_COMM_SELF">PETSC_COMM_SELF</a>,PETSC_ERR_ARG_WRONGSTATE,<font color="#666666">"Either iflags or ilengths should be provided"</font>);
<a name="line46"> 46: </a>    iflags_local = iflags_localm;
<a name="line47"> 47: </a>    <font color="#4169E1">for</font> (i=0; i&lt;size; i++) {
<a name="line48"> 48: </a>      <font color="#4169E1">if</font> (ilengths[i]) iflags_local[i] = 1;
<a name="line49"> 49: </a>      <font color="#4169E1">else</font> iflags_local[i] = 0;
<a name="line50"> 50: </a>    }
<a name="line51"> 51: </a>  } <font color="#4169E1">else</font> iflags_local = (<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a>*) iflags;

<a name="line53"> 53: </a>  <font color="#B22222">/* Post an allreduce to determine the numer of messages the current node will receive */</font>
<a name="line54"> 54: </a>  <a href="../../../docs/manualpages/Sys/MPIU_Allreduce.html#MPIU_Allreduce">MPIU_Allreduce</a>(iflags_local,recv_buf,size,MPI_INT,MPI_SUM,comm);
<a name="line55"> 55: </a>  *nrecvs = recv_buf[rank];

<a name="line57"> 57: </a>  <a href="../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</a>(recv_buf,iflags_localm);
<a name="line58"> 58: </a>  <font color="#4169E1">return</font>(0);
<a name="line59"> 59: </a>}


<a name="line62"> 62: </a><font color="#B22222">/*@C</font>
<a name="line63"> 63: </a><font color="#B22222">  <a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html#PetscGatherMessageLengths">PetscGatherMessageLengths</a> - Computes info about messages that a MPI-node will receive,</font>
<a name="line64"> 64: </a><font color="#B22222">  including (from-id,length) pairs for each message.</font>

<a name="line66"> 66: </a><font color="#B22222">  Collective</font>

<a name="line68"> 68: </a><font color="#B22222">  Input Parameters:</font>
<a name="line69"> 69: </a><font color="#B22222">+ comm      - Communicator</font>
<a name="line70"> 70: </a><font color="#B22222">. nsends    - number of messages that are to be sent.</font>
<a name="line71"> 71: </a><font color="#B22222">. nrecvs    - number of messages being received</font>
<a name="line72"> 72: </a><font color="#B22222">- ilengths  - an array of integers of length sizeof(comm)</font>
<a name="line73"> 73: </a><font color="#B22222">              a non zero ilengths[i] represent a message to i of length ilengths[i]</font>


<a name="line76"> 76: </a><font color="#B22222">  Output Parameters:</font>
<a name="line77"> 77: </a><font color="#B22222">+ onodes    - list of node-ids from which messages are expected</font>
<a name="line78"> 78: </a><font color="#B22222">- olengths  - corresponding message lengths</font>

<a name="line80"> 80: </a><font color="#B22222">  Level: developer</font>

<a name="line82"> 82: </a><font color="#B22222">  Notes:</font>
<a name="line83"> 83: </a><font color="#B22222">  With this info, the correct <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</a>() can be posted with the correct</font>
<a name="line84"> 84: </a><font color="#B22222">  from-id, with a buffer with the right amount of memory required.</font>

<a name="line86"> 86: </a><font color="#B22222">  The calling function deallocates the memory in onodes and olengths</font>

<a name="line88"> 88: </a><font color="#B22222">  To determine nrecevs, one can use <a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html#PetscGatherNumberOfMessages">PetscGatherNumberOfMessages</a>()</font>

<a name="line90"> 90: </a><font color="#B22222">.seealso: <a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html#PetscGatherNumberOfMessages">PetscGatherNumberOfMessages</a>()</font>
<a name="line91"> 91: </a><font color="#B22222">@*/</font>
<a name="line92"> 92: </a><strong><font color="#4169E1"><a name="PetscGatherMessageLengths"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</a>  <a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html#PetscGatherMessageLengths">PetscGatherMessageLengths</a>(<a href="../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</a> comm,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> nsends,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> nrecvs,const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> ilengths[],<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> **onodes,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> **olengths)</font></strong>
<a name="line93"> 93: </a>{
<a name="line95"> 95: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a>    size,rank,tag,i,j;
<a name="line96"> 96: </a>  MPI_Request    *s_waits  = NULL,*r_waits = NULL;
<a name="line97"> 97: </a>  MPI_Status     *w_status = NULL;

<a name="line100">100: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm,&amp;size);
<a name="line101">101: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(comm,&amp;rank);
<a name="line102">102: </a>  <a href="../../../docs/manualpages/Sys/PetscCommGetNewTag.html#PetscCommGetNewTag">PetscCommGetNewTag</a>(comm,&amp;tag);

<a name="line104">104: </a>  <font color="#B22222">/* cannot use <a href="../../../docs/manualpages/Sys/PetscMalloc3.html#PetscMalloc3">PetscMalloc3</a>() here because in the call to <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</a>() they MUST be contiguous */</font>
<a name="line105">105: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc2.html#PetscMalloc2">PetscMalloc2</a>(nrecvs+nsends,&amp;r_waits,nrecvs+nsends,&amp;w_status);
<a name="line106">106: </a>  s_waits = r_waits+nrecvs;

<a name="line108">108: </a>  <font color="#B22222">/* Post the Irecv to get the message length-info */</font>
<a name="line109">109: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs,olengths);
<a name="line110">110: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nrecvs; i++) {
<a name="line111">111: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</a>((*olengths)+i,1,MPI_INT,MPI_ANY_SOURCE,tag,comm,r_waits+i);
<a name="line112">112: </a>  }

<a name="line114">114: </a>  <font color="#B22222">/* Post the Isends with the message length-info */</font>
<a name="line115">115: </a>  <font color="#4169E1">for</font> (i=0,j=0; i&lt;size; ++i) {
<a name="line116">116: </a>    <font color="#4169E1">if</font> (ilengths[i]) {
<a name="line117">117: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Isend.html#MPI_Isend">MPI_Isend</a>((void*)(ilengths+i),1,MPI_INT,i,tag,comm,s_waits+j);
<a name="line118">118: </a>      j++;
<a name="line119">119: </a>    }
<a name="line120">120: </a>  }

<a name="line122">122: </a>  <font color="#B22222">/* Post waits on sends and receivs */</font>
<a name="line123">123: </a>  <font color="#4169E1">if</font> (nrecvs+nsends) {<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</a>(nrecvs+nsends,r_waits,w_status);}

<a name="line125">125: </a>  <font color="#B22222">/* Pack up the received data */</font>
<a name="line126">126: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs,onodes);
<a name="line127">127: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nrecvs; ++i) {
<a name="line128">128: </a>    (*onodes)[i] = w_status[i].MPI_SOURCE;
<a name="line129">129: </a><font color="#A020F0">#if defined(PETSC_HAVE_OMPI_MAJOR_VERSION)</font>
<a name="line130">130: </a>    <font color="#B22222">/* This line is a workaround for a bug in OpenMPI-2.1.1 distributed by Ubuntu-18.04.2 LTS.</font>
<a name="line131">131: </a><font color="#B22222">       It happens in self-to-self <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Send.html#MPI_Send">MPI_Send</a>/Recv using MPI_ANY_SOURCE for message matching. OpenMPI</font>
<a name="line132">132: </a><font color="#B22222">       does not put correct value in recv buffer. See also</font>
<a name="line133">133: </a><font color="#B22222">       https://lists.mcs.anl.gov/pipermail/petsc-dev/2019-July/024803.html</font>
<a name="line134">134: </a><font color="#B22222">       https://www.mail-archive.com/users@lists.open-mpi.org//msg33383.html</font>
<a name="line135">135: </a><font color="#B22222">     */</font>
<a name="line136">136: </a>    <font color="#4169E1">if</font> (w_status[i].MPI_SOURCE == rank) (*olengths)[i] = ilengths[rank];
<a name="line137">137: </a><font color="#A020F0">#endif</font>
<a name="line138">138: </a>  }
<a name="line139">139: </a>  <a href="../../../docs/manualpages/Sys/PetscFree2.html#PetscFree2">PetscFree2</a>(r_waits,w_status);
<a name="line140">140: </a>  <font color="#4169E1">return</font>(0);
<a name="line141">141: </a>}

<a name="line143">143: </a><font color="#B22222">/*@C</font>
<a name="line144">144: </a><font color="#B22222">  <a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths2.html#PetscGatherMessageLengths2">PetscGatherMessageLengths2</a> - Computes info about messages that a MPI-node will receive,</font>
<a name="line145">145: </a><font color="#B22222">  including (from-id,length) pairs for each message. Same functionality as <a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html#PetscGatherMessageLengths">PetscGatherMessageLengths</a>()</font>
<a name="line146">146: </a><font color="#B22222">  except it takes TWO ilenths and output TWO olengths.</font>

<a name="line148">148: </a><font color="#B22222">  Collective</font>

<a name="line150">150: </a><font color="#B22222">  Input Parameters:</font>
<a name="line151">151: </a><font color="#B22222">+ comm      - Communicator</font>
<a name="line152">152: </a><font color="#B22222">. nsends    - number of messages that are to be sent.</font>
<a name="line153">153: </a><font color="#B22222">. nrecvs    - number of messages being received</font>
<a name="line154">154: </a><font color="#B22222">- ilengths1, ilengths2 - array of integers of length sizeof(comm)</font>
<a name="line155">155: </a><font color="#B22222">              a non zero ilengths[i] represent a message to i of length ilengths[i]</font>

<a name="line157">157: </a><font color="#B22222">  Output Parameters:</font>
<a name="line158">158: </a><font color="#B22222">+ onodes    - list of node-ids from which messages are expected</font>
<a name="line159">159: </a><font color="#B22222">- olengths1, olengths2 - corresponding message lengths</font>

<a name="line161">161: </a><font color="#B22222">  Level: developer</font>

<a name="line163">163: </a><font color="#B22222">  Notes:</font>
<a name="line164">164: </a><font color="#B22222">  With this info, the correct <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</a>() can be posted with the correct</font>
<a name="line165">165: </a><font color="#B22222">  from-id, with a buffer with the right amount of memory required.</font>

<a name="line167">167: </a><font color="#B22222">  The calling function deallocates the memory in onodes and olengths</font>

<a name="line169">169: </a><font color="#B22222">  To determine nrecevs, one can use <a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html#PetscGatherNumberOfMessages">PetscGatherNumberOfMessages</a>()</font>

<a name="line171">171: </a><font color="#B22222">.seealso: <a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html#PetscGatherMessageLengths">PetscGatherMessageLengths</a>() and <a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html#PetscGatherNumberOfMessages">PetscGatherNumberOfMessages</a>()</font>
<a name="line172">172: </a><font color="#B22222">@*/</font>
<a name="line173">173: </a><strong><font color="#4169E1"><a name="PetscGatherMessageLengths2"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</a>  <a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths2.html#PetscGatherMessageLengths2">PetscGatherMessageLengths2</a>(<a href="../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</a> comm,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> nsends,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> nrecvs,const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> ilengths1[],const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> ilengths2[],<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> **onodes,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> **olengths1,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> **olengths2)</font></strong>
<a name="line174">174: </a>{
<a name="line176">176: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a>    size,tag,i,j,*buf_s = NULL,*buf_r = NULL,*buf_j = NULL;
<a name="line177">177: </a>  MPI_Request    *s_waits  = NULL,*r_waits = NULL;
<a name="line178">178: </a>  MPI_Status     *w_status = NULL;

<a name="line181">181: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm,&amp;size);
<a name="line182">182: </a>  <a href="../../../docs/manualpages/Sys/PetscCommGetNewTag.html#PetscCommGetNewTag">PetscCommGetNewTag</a>(comm,&amp;tag);

<a name="line184">184: </a>  <font color="#B22222">/* cannot use <a href="../../../docs/manualpages/Sys/PetscMalloc5.html#PetscMalloc5">PetscMalloc5</a>() because r_waits and s_waits must be contiguous for the call to <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</a>() */</font>
<a name="line185">185: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc4.html#PetscMalloc4">PetscMalloc4</a>(nrecvs+nsends,&amp;r_waits,2*nrecvs,&amp;buf_r,2*nsends,&amp;buf_s,nrecvs+nsends,&amp;w_status);
<a name="line186">186: </a>  s_waits = r_waits + nrecvs;

<a name="line188">188: </a>  <font color="#B22222">/* Post the Irecv to get the message length-info */</font>
<a name="line189">189: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs+1,olengths1);
<a name="line190">190: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs+1,olengths2);
<a name="line191">191: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nrecvs; i++) {
<a name="line192">192: </a>    buf_j = buf_r + (2*i);
<a name="line193">193: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</a>(buf_j,2,MPI_INT,MPI_ANY_SOURCE,tag,comm,r_waits+i);
<a name="line194">194: </a>  }

<a name="line196">196: </a>  <font color="#B22222">/* Post the Isends with the message length-info */</font>
<a name="line197">197: </a>  <font color="#4169E1">for</font> (i=0,j=0; i&lt;size; ++i) {
<a name="line198">198: </a>    <font color="#4169E1">if</font> (ilengths1[i]) {
<a name="line199">199: </a>      buf_j    = buf_s + (2*j);
<a name="line200">200: </a>      buf_j[0] = *(ilengths1+i);
<a name="line201">201: </a>      buf_j[1] = *(ilengths2+i);
<a name="line202">202: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Isend.html#MPI_Isend">MPI_Isend</a>(buf_j,2,MPI_INT,i,tag,comm,s_waits+j);
<a name="line203">203: </a>      j++;
<a name="line204">204: </a>    }
<a name="line205">205: </a>  }
<a name="line206">206: </a>  <font color="#4169E1">if</font> (j != nsends) <a href="../../../docs/manualpages/Sys/SETERRQ2.html#SETERRQ2">SETERRQ2</a>(<a href="../../../docs/manualpages/Sys/PETSC_COMM_SELF.html#PETSC_COMM_SELF">PETSC_COMM_SELF</a>,PETSC_ERR_PLIB,<font color="#666666">"j %d not equal to expected number of sends %d\n"</font>,j,nsends);

<a name="line208">208: </a>  <font color="#B22222">/* Post waits on sends and receivs */</font>
<a name="line209">209: </a>  <font color="#4169E1">if</font> (nrecvs+nsends) {<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</a>(nrecvs+nsends,r_waits,w_status);}


<a name="line212">212: </a>  <font color="#B22222">/* Pack up the received data */</font>
<a name="line213">213: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs+1,onodes);
<a name="line214">214: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nrecvs; ++i) {
<a name="line215">215: </a>    (*onodes)[i]    = w_status[i].MPI_SOURCE;
<a name="line216">216: </a>    buf_j           = buf_r + (2*i);
<a name="line217">217: </a>    (*olengths1)[i] = buf_j[0];
<a name="line218">218: </a>    (*olengths2)[i] = buf_j[1];
<a name="line219">219: </a>  }

<a name="line221">221: </a>  <a href="../../../docs/manualpages/Sys/PetscFree4.html#PetscFree4">PetscFree4</a>(r_waits,buf_r,buf_s,w_status);
<a name="line222">222: </a>  <font color="#4169E1">return</font>(0);
<a name="line223">223: </a>}

<a name="line225">225: </a><font color="#B22222">/*</font>

<a name="line227">227: </a><font color="#B22222">  Allocate a bufffer sufficient to hold messages of size specified in olengths.</font>
<a name="line228">228: </a><font color="#B22222">  And post Irecvs on these buffers using node info from onodes</font>

<a name="line230">230: </a><font color="#B22222"> */</font>
<a name="line231">231: </a><strong><font color="#4169E1"><a name="PetscPostIrecvInt"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</a>  PetscPostIrecvInt(<a href="../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</a> comm,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> tag,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> nrecvs,const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> onodes[],const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> olengths[],<a href="../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</a> ***rbuf,MPI_Request **r_waits)</font></strong>
<a name="line232">232: </a>{
<a name="line234">234: </a>  <a href="../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</a>       **rbuf_t,i,len = 0;
<a name="line235">235: </a>  MPI_Request    *r_waits_t;

<a name="line238">238: </a>  <font color="#B22222">/* compute memory required for recv buffers */</font>
<a name="line239">239: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nrecvs; i++) len += olengths[i];  <font color="#B22222">/* each message length */</font>

<a name="line241">241: </a>  <font color="#B22222">/* allocate memory for recv buffers */</font>
<a name="line242">242: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs+1,&amp;rbuf_t);
<a name="line243">243: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(len,&amp;rbuf_t[0]);
<a name="line244">244: </a>  <font color="#4169E1">for</font> (i=1; i&lt;nrecvs; ++i) rbuf_t[i] = rbuf_t[i-1] + olengths[i-1];

<a name="line246">246: </a>  <font color="#B22222">/* Post the receives */</font>
<a name="line247">247: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs,&amp;r_waits_t);
<a name="line248">248: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nrecvs; ++i) {
<a name="line249">249: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</a>(rbuf_t[i],olengths[i],<a href="../../../docs/manualpages/Sys/MPIU_INT.html#MPIU_INT">MPIU_INT</a>,onodes[i],tag,comm,r_waits_t+i);
<a name="line250">250: </a>  }

<a name="line252">252: </a>  *rbuf    = rbuf_t;
<a name="line253">253: </a>  *r_waits = r_waits_t;
<a name="line254">254: </a>  <font color="#4169E1">return</font>(0);
<a name="line255">255: </a>}

<a name="line257">257: </a><strong><font color="#4169E1"><a name="PetscPostIrecvScalar"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html#PetscErrorCode">PetscErrorCode</a>  PetscPostIrecvScalar(<a href="../../../docs/manualpages/Sys/MPI_Comm.html#MPI_Comm">MPI_Comm</a> comm,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> tag,<a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> nrecvs,const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> onodes[],const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a> olengths[],<a href="../../../docs/manualpages/Sys/PetscScalar.html#PetscScalar">PetscScalar</a> ***rbuf,MPI_Request **r_waits)</font></strong>
<a name="line258">258: </a>{
<a name="line260">260: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html#PetscMPIInt">PetscMPIInt</a>    i;
<a name="line261">261: </a>  <a href="../../../docs/manualpages/Sys/PetscScalar.html#PetscScalar">PetscScalar</a>    **rbuf_t;
<a name="line262">262: </a>  MPI_Request    *r_waits_t;
<a name="line263">263: </a>  <a href="../../../docs/manualpages/Sys/PetscInt.html#PetscInt">PetscInt</a>       len = 0;

<a name="line266">266: </a>  <font color="#B22222">/* compute memory required for recv buffers */</font>
<a name="line267">267: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nrecvs; i++) len += olengths[i];  <font color="#B22222">/* each message length */</font>

<a name="line269">269: </a>  <font color="#B22222">/* allocate memory for recv buffers */</font>
<a name="line270">270: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs+1,&amp;rbuf_t);
<a name="line271">271: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(len,&amp;rbuf_t[0]);
<a name="line272">272: </a>  <font color="#4169E1">for</font> (i=1; i&lt;nrecvs; ++i) rbuf_t[i] = rbuf_t[i-1] + olengths[i-1];

<a name="line274">274: </a>  <font color="#B22222">/* Post the receives */</font>
<a name="line275">275: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html#PetscMalloc1">PetscMalloc1</a>(nrecvs,&amp;r_waits_t);
<a name="line276">276: </a>  <font color="#4169E1">for</font> (i=0; i&lt;nrecvs; ++i) {
<a name="line277">277: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</a>(rbuf_t[i],olengths[i],<a href="../../../docs/manualpages/Sys/MPIU_SCALAR.html#MPIU_SCALAR">MPIU_SCALAR</a>,onodes[i],tag,comm,r_waits_t+i);
<a name="line278">278: </a>  }

<a name="line280">280: </a>  *rbuf    = rbuf_t;
<a name="line281">281: </a>  *r_waits = r_waits_t;
<a name="line282">282: </a>  <font color="#4169E1">return</font>(0);
<a name="line283">283: </a>}
</pre>
</body>

</html>
